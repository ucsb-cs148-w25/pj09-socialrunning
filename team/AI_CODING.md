Adil Ahmed - I switched to Cursor IDE and I have been using it to debug issues very fast. 
Instead of switching into GPT, Cursor already has my files and understands the context behind my code.
It is especially good for backend functions or package usage. I think it sometimes get confused on what files to use though.


Piyush Jadhav - For my experiment, I used ChatGPT to help me in writing better UI. One of the pages that I mainly worked on was the page where users select their cardio zone and duration, so I used AI to try to make the UI of it better. It was able to produce a visually appealing dropdown and a nice box for the duration and keeping it all centered. I think using ChatGPT was a good resource for UI because it does not really require a lot of files and all you need to do is tell it what you want the design to look like, making it efficient. The slight drawback was that it sometimes requires very clear instructions and telling it multiple times on what you want. In order for it to fully work the way I wanted it to work, I had to explain my full thought process and then it would get something wrong, so I would have to reiterate what I wanted sometimes. 

Nilay Kundu - For my AI experiment, I used both ChatGPT and Claude to for better scalability ideas for the app. More specifically, I want to address an issue where the IP Address has to be manually entered each time networks are switched. I asked both LLMs for possible solutions and a few of their ideas were: use a local network discovery approach (mDNS, react-native-zeroconf), use a static domain name, and use an environmental variable. When given a file to add the implementation of react-native-zeroconf, ChatGPT was able to understand the context of what the file is doing at each step and write code for the automatic ip address retrieval. However, the implementation caused an error, indicating that the new code does not seamlessly integrate with the other components on the page properly.

Ria Sinha - For my coding with AI experiment, I used ChatGPT to generate optimal unit tests for my code. I wanted to see how Chat GPT's responses would compare and contrast with my own strategies for unit testing. For my portion of the unit testing, I thought that it would be most optimal to test edge cases for the user inputs to ensure that it would correctly identify invalid inputs. I used the Jest library to test our frontend. When I asked Chat GPT for unit test ideas it recommended to use Jest & React Testing Library for unit and UI tests, while Appium/Detox could be used for mobile end-to-end automation. It also recommended using PyTest/JUnit to ensure backend API reliability.

Ron Kibel - For my experiment, I wanted to see the difference in efficiency when fixing bugs in existing features (as well as adding new features). I tried a combination of things---my previous go-to IDE had been Cursor, and depending on the task I prompt with different LLMs. I found that o3-mini works best with reviewing large files and fixing bugs or inconsistencies in the code, but sonnet-3.5 is generally better all around, particularly with identifying dependency issues and adding new files. My experiment change involved moving from Cursor to an agent-powered LLM (VSCode recently launched their Insiders IDE that has an agentic copilot) and I saw significant improvements in my efficiency---since the code was self-iterating, I was able to automatically fix bugs rather than having to understand the generated code and identifying faults, and the integration with the command line was a lifesaver. To ensure the output was correct, I would iterate through the app and try out all the features, noting what works and what doesn't, and asking the agent to dwell on these issues and fix them. Going forward, I plan to pivot to agentic AI, because its integration with the codebase as well as the terminal helps work through problems quickly and avoid the manual labor of code debugging.

Liv Jonokuchi - I used Cursor to make a "party animal" feature for our app just for fun and it resulted in a new page with a dancing panda (that I will not be merging into main haha). The tool was super useful and I can definitely see myself using it for future coding efforts. It initially made the page with the dancing panda but with no way to get to it, so I realized that it was really only as good as my prompt engineering for it. So I needed to iterate a couple times to get to the actual page but I tested it just by accepting the changes and then opening Expo and seeing if it did what I wanted it to. I didn't know how to check if it was fair use. It did a good job overall and was super helpful! I'd say it just needed to be explicitly asked to fix the navigation but I guess that was my own fault so user error. I will definitely be using it in the future! 

Aneesh Agarwal - For my coding experiment, I used Claude and ChatGPT to help build out the frontend UI for our app by creating scrolldown menu for our app that inlcluded the zone they were in and an input field for how long they wanted their playlist to be. I ended up going ahead with the code claude used, it was nicer format and compiled whereas ChatGPT's code had some issues compiling. I was pleasantly surpised with the quality of the code produced, I thought the UI was very simple to use and Claude had even added extra checks to make sure that a user's input for their playlist length to be a number and that too, something that was in a normal range of values. The only issue was that the code modified original variables that I wanted to keep for some of the UI components so I had to go back in and re-add them. However, I thought that the use of AI tools streamlined a lot for certain parts of the frontend development
